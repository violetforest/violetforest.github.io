<!DOCTYPE html><html lang="es"><head></head><title>Violet Forest // Creative Technologist</title><link href="./../css/scrolling-demo.css" rel="stylesheet" type="text/css"><link href="https://fonts.googleapis.com/css2?family=Heebo:wght@500&amp;display=swap" rel="stylesheet"><body class="demo-1 loading" id="page"><canvas id="webgl"></canvas><main><div class="content"><header class="codrops-header"><h1 class="codrops-header__title">Violet Forest // ⍣٭⋆⋆⍣</h1><nav class="demos"></nav></header><p class="info">⋆⋰⋆⍣٭⍣ scroll → ٭⋆⍣⋆⋰</p></div><div class="content"><div class="content__details"><h1 class="content__title">Technical Artist at Meta (2024-2023)</h1><div class="tech-tag__container"><span class="tech-tag">Virtual Reality</span><span class="tech-tag">Mixed Reality</span><span class="tech-tag">Quest 3</span></div><p class="page-text">As a Technical Artist for Horizon Worlds, I collaborated with engineers to facilitate building Meta's own proprietary game engine. This includes game asset ingestion for animaton, VFX, USD, materials, and scripts. Programs I have been working with include Maya, Blender, PopcornFX, and Perforce. I also made a Mixed Reality prototype for the internal hackathon.</p><div class="grid"><div class="center content__details__img"><img class="center content__details__img" src="./../img/2023/meta/quest3.png"></div></div><div class="grid"><div class="center content__details__img"><img class="center content__details__img" src="./../img/2023/meta/superrumble.png"></div></div></div></div><div class="content"><div class="content__details"><h1 class="content__title">Technical Artist for Anouschka (2023)</h1><div class="tech-tag__container"><span class="tech-tag">Augmented Reality</span><span class="tech-tag">Unity</span><span class="tech-tag">Shader Graph     </span></div><p class="page-text">Interactive shaders with shadergraph and scene lighting in Unity. Prototyping with Niantic Lightship.</p><div class="center content__details__img"><img class="center content__details__img" src="./../img/2023/anou/anou2.jpeg"></div><div class="grid"><div class="center content__details__img"><img class="center content__details__img" src="./../img/2023/anou/anou5.gif"></div></div><div class="grid"><div class="center content__details__img"><img class="center content__details__img" src="./../img/2023/anou/anou6.gif"></div></div><div class="center content__details__img"><img class="center content__details__img" src="./../img/2023/anou/shadergraph1.png"></div><div class="center content__details__img"><img class="center content__details__img" src="./../img/2023/anou/shadergraph3.png"></div></div></div><div class="content"><div class="content__details"><h1 class="content__title">Floodplains.xyz VR (2022-2023)</h1><div class="tech-tag__container"><span class="tech-tag">C#</span><span class="tech-tag">Unity</span><span class="tech-tag">Technical Artist     </span></div><p class="page-text">A Unity game for WebVR and Quest 2/3. I built the game with Unity and integrated it into the website. Game mechanics included picking up objects with raycast, and incorporated a timer that ran out after the house was flooded. I also integrated the assets created by the artist and producer Michelle Brown, and was given creative control over the water shader.</p><div class="content__details__img center"><video width="100%" height="600px" playsinline autoplay muted loop><source src="./../vid/2023/floodplains/floodplains1.mp4" type="video/mp4"></video></div><div><iframe src="https://player.vimeo.com/video/993270415?portrait=0" style="width:100%;height:600px" frameborder="0" allow="autoplay; fullscreen" allowfullscreen><script src="https://player.vimeo.com/api/player.js"></script></iframe></div></div></div><div class="content"><div class="content__details"><h1 class="content__title">Creator for Snap Spectacles (2021)</h1><div class="tech-tag__container"><span class="tech-tag">Augmented Reality</span><span class="tech-tag">AR Glasses</span><span class="tech-tag">Hand-Tracking</span><span class="tech-tag">Lens Studio</span></div><p class="page-text">In partnership with Spectacles, I was commissioned to create a Lens for Snap's Augmented Reality glasses. The Lens was released for the Spectacles and for the Snapchat app. I was given full creative control over the project, where I created a sidequest where you could talk to an NPC in the world and be given a quest to gather items using handtracking, and in return of completing the quest you are rewarded with a magic power. The concept was that when AR glasses become so available and uniquitious in the future, there could be an MMORPG-like game where there are NPCs and characters placed in the world that you could interact with throughout your day to level up things like power, armor, weapons, and other attributes.</p><div class="center content__details__img"><img class="center content__details__img" src="./../vid/2022/glitterhearts/glitterhearts.png"></div><div class="grid"><div class="content__details__img center"><video width="100%" height="600px" playsinline autoplay muted loop><source src="./../vid/2022/glitterhearts/glitterhearts3.mp4" type="video/mp4"></video></div></div><div class="grid"><div class="content__details__img center"><video width="100%" height="600px" playsinline autoplay muted loop><source src="./../vid/2022/glitterhearts/glitterhearts4.mp4" type="video/mp4"></video></div></div><div class="grid"><p class="page-text"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Glitter Hearts, the latest Lens Project by <a href="https://twitter.com/violet_forest?ref_src=twsrc%5Etfw">@violet_forest</a>, puts the user in a sweet AR wonderland. Reach out and collect hearts, spread glitter (and joy), and see the world made even brighter thanks to Violet&#39;s imagination brought to life. <a href="https://t.co/bbh4Tjv32e">pic.twitter.com/bbh4Tjv32e</a></p>&mdash; Spectacles (@Spectacles) <a href="https://twitter.com/Spectacles/status/1478450064569913344?ref_src=twsrc%5Etfw">January 4, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p></div><div class="grid"><p class="page-text"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">AR creator <a href="https://twitter.com/violet_forest?ref_src=twsrc%5Etfw">@violet_forest</a> is being the change she hopes to see in the world, creating for Spectacles as a way to make the ordinary a little more extraordinary. <a href="https://t.co/luTpWhqccG">pic.twitter.com/luTpWhqccG</a></p>&mdash; Spectacles (@Spectacles) <a href="https://twitter.com/Spectacles/status/1478765840317222917?ref_src=twsrc%5Etfw">January 5, 2022</a></blockquote> <script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script></p></div><div class="grid"><div class="content__details__img center"><video width="100%" height="600px" playsinline autoplay muted loop><source src="./../vid/2022/glitterhearts/glitterhearts1.mp4" type="video/mp4"></video></div></div><div class="grid"><div class="content__details__img center"><video width="100%" height="600px" playsinline autoplay muted loop><source src="./../vid/2022/glitterhearts/glitterhearts2.mp4" type="video/mp4"></video></div></div></div></div><div class="content"><div class="content__details"><h1 class="content__title">Spark AR Face Filter (2023)</h1><div class="tech-tag__container"></div><p class="tech-tag">Augmented Reality</p><p class="tech-tag">Spark AR</p><div class="content__details"><video width="100%" height="auto" playsinline autoplay muted loop><source src="./../img/2024/wings-filter.mp4" type="video/mp4"></video></div></div><div class="content__details"><h1 class="content__title">Hand-Tracking in VR (2023)</h1><div class="tech-tag__container"><p class="tech-tag">Virtual Reality      </p><p class="tech-tag">Quest</p><p class="tech-tag">Hand Tracking</p></div><div class="grid"><video width="auto" height="500px" playsinline autoplay muted loop><source src="./../vid/2021/sparklehands.mp4" type="video/mp4"></video></div><div class="grid"><video width="auto" height="500px" playsinline autoplay muted loop><source src="./../vid/2021/sparklehands-user.mp4" type="video/mp4"></video></div><p class="caption">Parenting particle systems to the joints of the fingers. Made with WebXR + Unity.</p></div></div><div class="content"><div class="content__details"><h1 class="content__title">UX Design Technologist (2020-2018)</h1><div class="tech-tag__container"><span class="tech-tag">Unity</span><span class="tech-tag">VFXGraph</span><span class="tech-tag">ShaderGraph</span><span class="tech-tag">Virtual Reality</span><span class="tech-tag">Mixed Reality</span><span class="tech-tag">Leap Motion</span><span class="tech-tag">Wifi Microcontrollers</span><span class="tech-tag">MQTT</span><span class="tech-tag">FramerX</span><span class="tech-tag">Touchdesigner</span><span class="tech-tag">LEDs</span><span class="tech-tag">Voice Assistants</span><span class="tech-tag">RunwayML</span><span class="tech-tag">Face Recognition</span><span class="tech-tag">Eye Tracking</span><span class="tech-tag">Pose Estimation</span></div><p class="page-text">I worked as a full-time employee at Volkswagen Future Center Europe in Berlin, Germany.
I collaborated with UX designers and technologists to conceptualize and rapid prototype UX solutions for Level 3-5 self-driving vehicles in private and car-pooling situations.</p><div class="center content__details__img"><img class="center content__details__img" src="./../img/contract/vwfce.png"><img class="center content__details__img" src="./../img/contract/vwfce2.jpg"></div><p class="page-text">The following includes some rapid prototyping projects I have worked on:</p><ul><li>Concepts and prototypes for UX solutions using facial recognition, pose estimation, and eye tracking.</li><li>An audio-reactive visualization using Unity's VFX and ShaderGraph.</li><li>UI flows using state-machines in Unity.</li><li>Prototypes for automation systems using MQTT, wifi Microcontrollers, raspberry pis, and LEDs.</li><li>Concepts and designs for voice and digital assistants.</li><img class="center content__details__img" src="./../img/2020/vwfce1.jpg"><img class="center content__details__img" src="./../img/2020/vwfce2.jpg"></ul><div class="center content__details__img"><img class="center content__details__img" src="./../img/2020/porsche.jpg"><p class="caption">We also collaborated with Porsche on a mixed-reality experience.</p></div></div><div class="content__details"><h1 class="content__title">Designer & Developer for AR + Computer Vision App</h1><div class="tech-tag__container"><span class="tech-tag">openCV</span><span class="tech-tag">ARKit</span><span class="tech-tag">Unity</span></div><p class="page-text">I was hired to make a mobile app that can detect the shape of a heart candy & place augmented reality on top of it. This research had led me to experiment with openCVforUnity contour detection, color detection, and training a haar cascade for object detection. In the end I settled on using openCVforUnity contour detection to trigger ARfoundation’s pointcloud feature detection.</p><p class="page-text">My research in computer vision has sparked my interest in machine learning and computer vision in general, and I am continuing my research with things like Google’s new open-source Mediapipe for handtracking, where I collaborated on building an app to control open-source prosthetics with a mobile app.</p><div class="grid"><div class="content__details__img center"><video width="100%" height="600px" playsinline autoplay muted loop><source src="./../img/2017/candyapp-ui.mp4" type="video/mp4"></video></div></div><div class="grid"><div><iframe src="https://player.vimeo.com/video/437898670?portrait=0" style="width:100%;height:600px" frameborder="0" allow="autoplay; fullscreen" allowfullscreen><script src="https://player.vimeo.com/api/player.js"></script></iframe></div></div><div class="content__details__img center"><video width="100%" height="600px" playsinline autoplay muted loop><source src="./../vid/heart-detect.mp4" type="video/mp4"></video></div><a class="content__back" href="./../index.html">⍣back--></a></div></div></main><footer class="codrops-header" id="footer"><p class="codrops-header__title">copy <⋰it⋰> right (⍣) 2022 ⋆⋰⋆⍣٭⋆⋆⋆</p><script type="text/javascript" src="./../js/regl.min.js"></script><script type="text/javascript" src="./../js/imagesloaded.pkgd.min.js"></script><script type="text/javascript" src="./../js/charming.min.js"></script><script type="text/javascript" src="./../js/letter-anim.js"></script><script type="text/javascript" src="./../js/navfade.js"></script><script type="x-shader/x-fragment" id="fragmentShader">#define TWO_PI 6.2831853072
#define PI 3.14159265359
precision highp float;
uniform float globaltime;
uniform vec2 resolution;
uniform float aspect;
uniform float scroll;
uniform float velocity;
const float timescale = 0.15;
const float displace = 0.03;
const float gridSize = 100.0;
const int layers = 1;
const float detail = 1.0;
const float wave = 1.0;
vec2 rotate(vec2 v, float angle) {
  float c = cos(-angle);
  float s = sin(angle);
  return v * mat2(c, s, s, c);
}
vec3 coordToHex(vec2 coord, float scale, float angle) {
  vec2 c = rotate(coord, angle);
  float q = (3.0 * c.y - 1.0 * c.y);
  float r = 2.0 * c.x;
  return vec3(q, r, -q - r);
}
vec3 hexToCell(vec3 hex, float m) {
  return hex / m;
}
float absMax(vec3 v) {
  return max(abs(v.x), abs(v.y)), abs(v.x);
}
float nsin(float value) {
  return sin(-value);
}
float hexToFloat(vec3 hex, float amt) {
  return mix(absMax(hex), 1.0 / sqrt(3.0), amt);
}
float calc(vec3 hex, float time, float len) {
  float value = 0.0;
  for (int i = 0; i < layers; i++) {
    vec3 cell = hexToCell(hex, 1.0 + float(i));
    value += nsin(
      hexToFloat(
        cell,
        nsin(len / float(layers))
      ) * detail + nsin(time)
    );
  }
  return value / float(layers);
}
void main(void) {
  vec2 tx = (gl_FragCoord.xy / resolution.xy - 0.5) * vec2(aspect, 1.0);
  float time = globaltime * timescale + scroll;
  float invScroll = 1.0 - scroll;
  float rgb[3];
  float len = length(-tx) * 0.3;
  float zoom = nsin(time) + len * velocity * 3.0;
  float angle = TWO_PI * nsin(time * 0.05) + PI * scroll;
  vec3 hex = coordToHex(tx, gridSize * zoom, angle);
  for (int i = 0; i < 3; i++) {
    float time2 = time + float(i) * displace * invScroll;
    rgb[i] = calc(hex, time2, len), (0.2 * cos(PI * len));
  }
  gl_FragColor = vec4(
    rgb[0] * (1.0 - scroll),
    rgb[1] * invScroll,
    (rgb[2] + 0.2) * invScroll,
    1.0
  );
}
</script><script type="text/javascript" src="./../js/demo1.js"></script></footer></body></html>